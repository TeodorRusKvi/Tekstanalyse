{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last inn 'X_train_LSTM' fra en CSV-fil\n",
    "X_df = pd.read_csv(url_data+'X_tensorflow.csv')\n",
    "# Konverter hele DataFrame til et NumPy array\n",
    "X = X_df.to_numpy()\n",
    "\n",
    "# Last inn 'y_train_LSTM' fra en CSV-fil\n",
    "y_df = pd.read_csv(url_data+'y_liberal.csv')\n",
    "# Konverter hele DataFrame til et NumPy array\n",
    "y = y_df.to_numpy()\n",
    "\n",
    "# Last inn 'y_train_LSTM' fra en CSV-fil\n",
    "embeddings_GloVe = pd.read_csv(url_data+'embeddings_glove.csv')\n",
    "# Konverter hele DataFrame til et NumPy array\n",
    "embeddings_GloVe = embeddings_GloVe.to_numpy()\n",
    "\n",
    "print('Shape of label tensor:', y.shape)\n",
    "print('Shape of X:', X.shape)\n",
    "print('Shape of embeddings_GloVe:', embeddings_GloVe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "#batch_size = None\n",
    "#batch_size=64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(20,)))\n",
    "# Adding the Embedding layer with pre-trained weights and specifying input_length\n",
    "model.add(Embedding(input_dim=embeddings_GloVe.shape[0],\n",
    "                    output_dim=embeddings_GloVe.shape[1],\n",
    "                    weights=[embeddings_GloVe],\n",
    "                    trainable=False))\n",
    "\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Conv1D(filters=64, kernel_size=1, activation='relu'))\n",
    "# It's common to add a MaxPooling layer after a Conv layer to reduce dimensionality\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Bidirectional(LSTM(64, # Number of hidden states, number of reccurent units for each vector\n",
    "    activation='tanh',\n",
    "    recurrent_activation='sigmoid',\n",
    "    recurrent_dropout=0.2,\n",
    "    return_sequences=False)))\n",
    "\n",
    "model.add(Dense(77, activation='relu'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "\n",
    "\n",
    "# history = model.fit(X_train_LSTM, y_train_LSTM,\n",
    "#                     epochs=20, # Adjust based on your needs\n",
    "#                     validation_split=0.2,\n",
    "#                     batch_size=64,\n",
    "#                     callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
