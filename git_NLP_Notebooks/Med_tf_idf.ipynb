{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bugat\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset to see its structure\n",
    "df = pd.read_csv(r'C:\\Users\\bugat\\OneDrive - NTNU\\Vår 2024\\Tekstanalyse\\Prosjektoppgave\\Political_detection\\new_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed'].fillna('', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_text</th>\n",
       "      <th>Political Lean</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>SubredditEncoded</th>\n",
       "      <th>Processed</th>\n",
       "      <th>Dependency_Tags</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No matter who someone is, how they look like, ...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>socialism</td>\n",
       "      <td>14</td>\n",
       "      <td>matter someone look like language speak wear r...</td>\n",
       "      <td>['ROOT', 'nsubj', 'ccomp', 'prep', 'compound',...</td>\n",
       "      <td>VERB PRON VERB ADP NOUN NOUN NOUN VERB ADJ NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden speech draws 38.2 million U.S. TV viewers 0</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>10</td>\n",
       "      <td>biden speech draw million tv viewer</td>\n",
       "      <td>['compound', 'nsubj', 'ROOT', 'nummod', 'compo...</td>\n",
       "      <td>PROPN NOUN VERB NUM NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State of the union Who watched the state of th...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>DemocraticSocialism</td>\n",
       "      <td>2</td>\n",
       "      <td>state union watch state union last night opinion</td>\n",
       "      <td>['compound', 'nsubj', 'ROOT', 'compound', 'dob...</td>\n",
       "      <td>NOUN PROPN VERB NOUN NOUN ADJ NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Should Just Give Poor People Money 0</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>6</td>\n",
       "      <td>give poor people money</td>\n",
       "      <td>['ROOT', 'amod', 'dative', 'dobj']</td>\n",
       "      <td>VERB ADJ NOUN NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do it for the Dew 0</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>10</td>\n",
       "      <td>dew</td>\n",
       "      <td>['ROOT']</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12849</th>\n",
       "      <td>Ron Paul’s Spirited Defense of WikiLeaks &amp; Fre...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>ron paul spirited defense wikileaks free infor...</td>\n",
       "      <td>['compound', 'nsubj', 'amod', 'compound', 'nsu...</td>\n",
       "      <td>PROPN PROPN VERB NOUN NOUN ADJ NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12850</th>\n",
       "      <td>“Anarcho-capitalism, in my opinion, is a doctr...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>anarcho capitalism opinion doctrinal system ev...</td>\n",
       "      <td>['nmod', 'compound', 'compound', 'amod', 'nsub...</td>\n",
       "      <td>PROPN PROPN NOUN ADJ NOUN ADV VERB AUX VERB VE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>Mises Wiki is a wiki project dedicated to the ...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>mises wiki wiki project dedicate advancement a...</td>\n",
       "      <td>['ROOT', 'compound', 'compound', 'nmod', 'amod...</td>\n",
       "      <td>VERB ADJ NOUN NOUN NOUN NOUN ADJ NOUN NOUN VER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>Fireman Protection Monopoly - Is This Failed C...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>fireman protection monopoly failed capitalism</td>\n",
       "      <td>['compound', 'compound', 'nsubj', 'ROOT', 'dobj']</td>\n",
       "      <td>PROPN PROPN NOUN VERB NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12853</th>\n",
       "      <td>Can this Wikipedia Article be Better Written? ...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>wikipedia article better write go listen writi...</td>\n",
       "      <td>['compound', 'nsubj', 'advmod', 'ccomp', 'dobj...</td>\n",
       "      <td>NOUN NOUN ADV VERB NOUN VERB VERB PROPN NOUN X...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12854 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                All_text Political Lean  \\\n",
       "0      No matter who someone is, how they look like, ...        Liberal   \n",
       "1      Biden speech draws 38.2 million U.S. TV viewers 0        Liberal   \n",
       "2      State of the union Who watched the state of th...        Liberal   \n",
       "3                We Should Just Give Poor People Money 0        Liberal   \n",
       "4                                    Do it for the Dew 0        Liberal   \n",
       "...                                                  ...            ...   \n",
       "12849  Ron Paul’s Spirited Defense of WikiLeaks & Fre...   Conservative   \n",
       "12850  “Anarcho-capitalism, in my opinion, is a doctr...   Conservative   \n",
       "12851  Mises Wiki is a wiki project dedicated to the ...   Conservative   \n",
       "12852  Fireman Protection Monopoly - Is This Failed C...   Conservative   \n",
       "12853  Can this Wikipedia Article be Better Written? ...   Conservative   \n",
       "\n",
       "                 Subreddit  SubredditEncoded  \\\n",
       "0                socialism                14   \n",
       "1                democrats                10   \n",
       "2      DemocraticSocialism                 2   \n",
       "3          SocialDemocracy                 6   \n",
       "4                democrats                10   \n",
       "...                    ...               ...   \n",
       "12849    anarchocapitalism                 8   \n",
       "12850    anarchocapitalism                 8   \n",
       "12851    anarchocapitalism                 8   \n",
       "12852    anarchocapitalism                 8   \n",
       "12853    anarchocapitalism                 8   \n",
       "\n",
       "                                               Processed  \\\n",
       "0      matter someone look like language speak wear r...   \n",
       "1                    biden speech draw million tv viewer   \n",
       "2       state union watch state union last night opinion   \n",
       "3                                 give poor people money   \n",
       "4                                                    dew   \n",
       "...                                                  ...   \n",
       "12849  ron paul spirited defense wikileaks free infor...   \n",
       "12850  anarcho capitalism opinion doctrinal system ev...   \n",
       "12851  mises wiki wiki project dedicate advancement a...   \n",
       "12852      fireman protection monopoly failed capitalism   \n",
       "12853  wikipedia article better write go listen writi...   \n",
       "\n",
       "                                         Dependency_Tags  \\\n",
       "0      ['ROOT', 'nsubj', 'ccomp', 'prep', 'compound',...   \n",
       "1      ['compound', 'nsubj', 'ROOT', 'nummod', 'compo...   \n",
       "2      ['compound', 'nsubj', 'ROOT', 'compound', 'dob...   \n",
       "3                     ['ROOT', 'amod', 'dative', 'dobj']   \n",
       "4                                               ['ROOT']   \n",
       "...                                                  ...   \n",
       "12849  ['compound', 'nsubj', 'amod', 'compound', 'nsu...   \n",
       "12850  ['nmod', 'compound', 'compound', 'amod', 'nsub...   \n",
       "12851  ['ROOT', 'compound', 'compound', 'nmod', 'amod...   \n",
       "12852  ['compound', 'compound', 'nsubj', 'ROOT', 'dobj']   \n",
       "12853  ['compound', 'nsubj', 'advmod', 'ccomp', 'dobj...   \n",
       "\n",
       "                                                pos_tags  \n",
       "0      VERB PRON VERB ADP NOUN NOUN NOUN VERB ADJ NOU...  \n",
       "1                          PROPN NOUN VERB NUM NOUN NOUN  \n",
       "2                NOUN PROPN VERB NOUN NOUN ADJ NOUN NOUN  \n",
       "3                                     VERB ADJ NOUN NOUN  \n",
       "4                                                   NOUN  \n",
       "...                                                  ...  \n",
       "12849                PROPN PROPN VERB NOUN NOUN ADJ NOUN  \n",
       "12850  PROPN PROPN NOUN ADJ NOUN ADV VERB AUX VERB VE...  \n",
       "12851  VERB ADJ NOUN NOUN NOUN NOUN ADJ NOUN NOUN VER...  \n",
       "12852                         PROPN PROPN NOUN VERB NOUN  \n",
       "12853  NOUN NOUN ADV VERB NOUN VERB VERB PROPN NOUN X...  \n",
       "\n",
       "[12854 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()  # Bruk et sett for å lagre unike ord\n",
    "\n",
    "for text in df['Processed']:\n",
    "    words = text.split()  # Splitt tekst i ord, antar at mellomrom er separator\n",
    "    unique_words.update(words)  # Legger til ordene i settet, som automatisk fjerner duplikater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12854"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df['Processed'].to_list()\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bugat\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 120)               2683560   \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 32)                3872      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 15)                495       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2687927 (10.25 MB)\n",
      "Trainable params: 2687927 (10.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Trinn 1: TF-IDF Vektorisering\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=len(unique_words)+1) # Begrenser til de 10 000 mest frekvente ordene\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['Processed']).toarray()\n",
    "\n",
    "# Trinn 2: Label Encoding av `Subreddit`\n",
    "labels = df['SubredditEncoded'].values\n",
    "labels = labels.reshape(-1, 1)\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "all_labels = one_hot_encoder.fit_transform(labels)\n",
    "\n",
    "# Trinn 3: Tren-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# y_train_encoded = to_categorical(y_train, 15)\n",
    "# y_test_encoded = to_categorical(y_test, 15)\n",
    "\n",
    "# Opprette modellen\n",
    "model = Sequential()\n",
    "\n",
    "# Legg til Dense-lag\n",
    "model.add(Dense(120, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout for å redusere overtilpasning\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# Legg til output-laget. Antall enheter skal matche antall unike klasser\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "# Kompilere modellen\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary for å se detaljer om modellarkitekturen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "161/161 [==============================] - 6s 31ms/step - loss: 2.6316 - accuracy: 0.1168 - val_loss: 2.4757 - val_accuracy: 0.2520\n",
      "Epoch 2/12\n",
      "161/161 [==============================] - 5s 28ms/step - loss: 2.2435 - accuracy: 0.2829 - val_loss: 2.0796 - val_accuracy: 0.3329\n",
      "Epoch 3/12\n",
      "161/161 [==============================] - 4s 28ms/step - loss: 1.8157 - accuracy: 0.4146 - val_loss: 1.9102 - val_accuracy: 0.3839\n",
      "Epoch 4/12\n",
      "161/161 [==============================] - 7s 43ms/step - loss: 1.4980 - accuracy: 0.5301 - val_loss: 1.8756 - val_accuracy: 0.3862\n",
      "Epoch 5/12\n",
      "161/161 [==============================] - 8s 50ms/step - loss: 1.2509 - accuracy: 0.6104 - val_loss: 1.9008 - val_accuracy: 0.3917\n",
      "Epoch 6/12\n",
      "161/161 [==============================] - 6s 35ms/step - loss: 1.0587 - accuracy: 0.6759 - val_loss: 1.9529 - val_accuracy: 0.3855\n",
      "Epoch 7/12\n",
      "161/161 [==============================] - 5s 33ms/step - loss: 0.9073 - accuracy: 0.7206 - val_loss: 2.0345 - val_accuracy: 0.3796\n",
      "Epoch 8/12\n",
      "161/161 [==============================] - 5s 33ms/step - loss: 0.7913 - accuracy: 0.7569 - val_loss: 2.1164 - val_accuracy: 0.3777\n",
      "Epoch 9/12\n",
      "161/161 [==============================] - 5s 31ms/step - loss: 0.6964 - accuracy: 0.7872 - val_loss: 2.2395 - val_accuracy: 0.3641\n",
      "Epoch 10/12\n",
      "161/161 [==============================] - 5s 32ms/step - loss: 0.6114 - accuracy: 0.8053 - val_loss: 2.3182 - val_accuracy: 0.3644\n",
      "Epoch 11/12\n",
      "161/161 [==============================] - 5s 32ms/step - loss: 0.5475 - accuracy: 0.8299 - val_loss: 2.4297 - val_accuracy: 0.3582\n",
      "Epoch 12/12\n",
      "161/161 [==============================] - 5s 31ms/step - loss: 0.5012 - accuracy: 0.8441 - val_loss: 2.5357 - val_accuracy: 0.3563\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=12, # Adjust based on your needs\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}, Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "plt.title('Accuracy score')\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.title('Loss value')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
