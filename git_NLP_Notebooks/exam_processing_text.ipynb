{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset to see its structure\n",
    "df = pd.read_csv(r'C:\\Users\\bugat\\OneDrive - NTNU\\Vår 2024\\Tekstanalyse\\Prosjektoppgave\\Political_detection\\new_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 12854/12854 [01:53<00:00, 113.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_text</th>\n",
       "      <th>Political_Lean</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>subreddit_encoded</th>\n",
       "      <th>Processed</th>\n",
       "      <th>Dependency_Tags</th>\n",
       "      <th>POS_Tags</th>\n",
       "      <th>Named_Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No matter who someone is, how they look like, ...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>socialism</td>\n",
       "      <td>14</td>\n",
       "      <td>matter look like language speak wear remember ...</td>\n",
       "      <td>['advmod', 'ROOT', 'prep', 'compound', 'compou...</td>\n",
       "      <td>['ADV', 'VERB', 'ADP', 'NOUN', 'NOUN', 'NOUN',...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden speech draws 38.2 million US TV viewers 0</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>10</td>\n",
       "      <td>biden speech draw million tv viewer</td>\n",
       "      <td>['compound', 'nsubj', 'ROOT', 'nummod', 'compo...</td>\n",
       "      <td>['PROPN', 'NOUN', 'VERB', 'NUM', 'PROPN', 'NOU...</td>\n",
       "      <td>['biden speech draw million (ORG)', 'U.S. (GPE)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State of the union Who watched the state of th...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>DemocraticSocialism</td>\n",
       "      <td>2</td>\n",
       "      <td>state union watch state union night opinion</td>\n",
       "      <td>['compound', 'nsubj', 'ROOT', 'compound', 'com...</td>\n",
       "      <td>['NOUN', 'PROPN', 'VERB', 'NOUN', 'PROPN', 'NO...</td>\n",
       "      <td>['state union watch state union (ORG)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We Should Just Give Poor People Money 0</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>6</td>\n",
       "      <td>poor people money</td>\n",
       "      <td>['amod', 'compound', 'ROOT']</td>\n",
       "      <td>['ADJ', 'NOUN', 'NOUN']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do it for the Dew 0</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>democrats</td>\n",
       "      <td>10</td>\n",
       "      <td>dew</td>\n",
       "      <td>['ROOT']</td>\n",
       "      <td>['NOUN']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12849</th>\n",
       "      <td>Ron Paul’s Spirited Defense of WikiLeaks &amp; Fre...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>ron paul spirited defense wikileaks free infor...</td>\n",
       "      <td>['compound', 'nsubj', 'amod', 'compound', 'nsu...</td>\n",
       "      <td>['PROPN', 'PROPN', 'VERB', 'NOUN', 'NOUN', 'AD...</td>\n",
       "      <td>['ron paul (PERSON)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12850</th>\n",
       "      <td>“Anarcho-capitalism, in my opinion, is a doctr...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>anarcho capitalism opinion doctrinal system im...</td>\n",
       "      <td>['nmod', 'compound', 'compound', 'amod', 'nsub...</td>\n",
       "      <td>['PROPN', 'PROPN', 'NOUN', 'ADJ', 'NOUN', 'VER...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>Mises Wiki is a wiki project dedicated to the ...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>mises wiki wiki project dedicate advancement a...</td>\n",
       "      <td>['ROOT', 'compound', 'compound', 'nmod', 'amod...</td>\n",
       "      <td>['VERB', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'NOUN'...</td>\n",
       "      <td>['mises wiki wiki (PERSON)', 'austrian (NORP)'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>Fireman Protection Monopoly - Is This Failed C...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>fireman protection monopoly failed capitalism</td>\n",
       "      <td>['compound', 'compound', 'nsubj', 'ROOT', 'dobj']</td>\n",
       "      <td>['PROPN', 'PROPN', 'NOUN', 'VERB', 'NOUN']</td>\n",
       "      <td>['fireman protection monopoly (ORG)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12853</th>\n",
       "      <td>Can this Wikipedia Article be Better Written? ...</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>anarchocapitalism</td>\n",
       "      <td>8</td>\n",
       "      <td>wikipedia article better write listen writing ...</td>\n",
       "      <td>['compound', 'nsubj', 'advmod', 'ROOT', 'dobj'...</td>\n",
       "      <td>['NOUN', 'NOUN', 'ADV', 'VERB', 'NOUN', 'VERB'...</td>\n",
       "      <td>['wikipedia article (ORG)']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12854 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                All_text Political_Lean  \\\n",
       "0      No matter who someone is, how they look like, ...        Liberal   \n",
       "1        Biden speech draws 38.2 million US TV viewers 0        Liberal   \n",
       "2      State of the union Who watched the state of th...        Liberal   \n",
       "3                We Should Just Give Poor People Money 0        Liberal   \n",
       "4                                    Do it for the Dew 0        Liberal   \n",
       "...                                                  ...            ...   \n",
       "12849  Ron Paul’s Spirited Defense of WikiLeaks & Fre...   Conservative   \n",
       "12850  “Anarcho-capitalism, in my opinion, is a doctr...   Conservative   \n",
       "12851  Mises Wiki is a wiki project dedicated to the ...   Conservative   \n",
       "12852  Fireman Protection Monopoly - Is This Failed C...   Conservative   \n",
       "12853  Can this Wikipedia Article be Better Written? ...   Conservative   \n",
       "\n",
       "                 Subreddit  subreddit_encoded  \\\n",
       "0                socialism                 14   \n",
       "1                democrats                 10   \n",
       "2      DemocraticSocialism                  2   \n",
       "3          SocialDemocracy                  6   \n",
       "4                democrats                 10   \n",
       "...                    ...                ...   \n",
       "12849    anarchocapitalism                  8   \n",
       "12850    anarchocapitalism                  8   \n",
       "12851    anarchocapitalism                  8   \n",
       "12852    anarchocapitalism                  8   \n",
       "12853    anarchocapitalism                  8   \n",
       "\n",
       "                                               Processed  \\\n",
       "0      matter look like language speak wear remember ...   \n",
       "1                    biden speech draw million tv viewer   \n",
       "2            state union watch state union night opinion   \n",
       "3                                      poor people money   \n",
       "4                                                    dew   \n",
       "...                                                  ...   \n",
       "12849  ron paul spirited defense wikileaks free infor...   \n",
       "12850  anarcho capitalism opinion doctrinal system im...   \n",
       "12851  mises wiki wiki project dedicate advancement a...   \n",
       "12852      fireman protection monopoly failed capitalism   \n",
       "12853  wikipedia article better write listen writing ...   \n",
       "\n",
       "                                         Dependency_Tags  \\\n",
       "0      ['advmod', 'ROOT', 'prep', 'compound', 'compou...   \n",
       "1      ['compound', 'nsubj', 'ROOT', 'nummod', 'compo...   \n",
       "2      ['compound', 'nsubj', 'ROOT', 'compound', 'com...   \n",
       "3                           ['amod', 'compound', 'ROOT']   \n",
       "4                                               ['ROOT']   \n",
       "...                                                  ...   \n",
       "12849  ['compound', 'nsubj', 'amod', 'compound', 'nsu...   \n",
       "12850  ['nmod', 'compound', 'compound', 'amod', 'nsub...   \n",
       "12851  ['ROOT', 'compound', 'compound', 'nmod', 'amod...   \n",
       "12852  ['compound', 'compound', 'nsubj', 'ROOT', 'dobj']   \n",
       "12853  ['compound', 'nsubj', 'advmod', 'ROOT', 'dobj'...   \n",
       "\n",
       "                                                POS_Tags  \\\n",
       "0      ['ADV', 'VERB', 'ADP', 'NOUN', 'NOUN', 'NOUN',...   \n",
       "1      ['PROPN', 'NOUN', 'VERB', 'NUM', 'PROPN', 'NOU...   \n",
       "2      ['NOUN', 'PROPN', 'VERB', 'NOUN', 'PROPN', 'NO...   \n",
       "3                                ['ADJ', 'NOUN', 'NOUN']   \n",
       "4                                               ['NOUN']   \n",
       "...                                                  ...   \n",
       "12849  ['PROPN', 'PROPN', 'VERB', 'NOUN', 'NOUN', 'AD...   \n",
       "12850  ['PROPN', 'PROPN', 'NOUN', 'ADJ', 'NOUN', 'VER...   \n",
       "12851  ['VERB', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'NOUN'...   \n",
       "12852         ['PROPN', 'PROPN', 'NOUN', 'VERB', 'NOUN']   \n",
       "12853  ['NOUN', 'NOUN', 'ADV', 'VERB', 'NOUN', 'VERB'...   \n",
       "\n",
       "                                          Named_Entities  \n",
       "0                                                     []  \n",
       "1      ['biden speech draw million (ORG)', 'U.S. (GPE)']  \n",
       "2                ['state union watch state union (ORG)']  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "12849                              ['ron paul (PERSON)']  \n",
       "12850                                                 []  \n",
       "12851  ['mises wiki wiki (PERSON)', 'austrian (NORP)'...  \n",
       "12852              ['fireman protection monopoly (ORG)']  \n",
       "12853                        ['wikipedia article (ORG)']  \n",
       "\n",
       "[12854 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tq.pandas(desc='Processing')\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a list of stopwords (this is just an example, ensure to load or define a comprehensive list)\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Function to tokenize and lemmatize a single text, while removing stopwords and keeping certain abbreviations\n",
    "def tokenize_and_lemmatize_text(text):\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "    lemmatized_tokens = []\n",
    "    for token in (doc):\n",
    "        # Check if the token matches specific abbreviations or consists of alphabetic characters\n",
    "        if token.text in ['U.S.', 'U.S.A.'] or (token.is_alpha and token.lemma_.lower() not in stop_words):\n",
    "            # Directly add the abbreviations or lemmatize and lower-case other tokens\n",
    "            token_to_add = token.text if token.text in ['U.S.', 'U.S.A.'] else token.lemma_.lower()\n",
    "            lemmatized_tokens.append(token_to_add)\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "\n",
    "# Apply the tokenization and lemmatization function to each row in the column\n",
    "df['Processed'] = df['All_text'].progress_apply(tokenize_and_lemmatize_text)\n",
    "\n",
    "# Show the first few rows to verify the changes\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed'] = df['Processed'].replace(['U.S.', 'U.S.A.'], 'US', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_features(text):\n",
    "    doc = nlp(text)\n",
    "    dependency_tags = [token.dep_ for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    \n",
    "    # Extract named entities, ensure to join multiple-word entities, and represent them with their labels\n",
    "    named_entities = [f\"{ent.text} ({ent.label_})\" for ent in doc.ents]\n",
    "    \n",
    "    return dependency_tags, pos_tags, named_entities\n",
    "\n",
    "# Apply the function to the 'Processed' column and create new columns for each feature\n",
    "df['Dependency_Tags'], df['POS_Tags'], df['Named_Entities'] = zip(*df['Processed'].apply(extract_text_features))\n",
    "\n",
    "# Show the first few rows to verify the new columns\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
